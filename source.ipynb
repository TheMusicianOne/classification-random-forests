{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're getting the data\n",
    "path = \"C:/Users/yusse/Documents/dataproject/trainData/32_train.csv\"\n",
    "df = pd.read_csv(path, header=None)\n",
    "df = df.assign(label=[(lambda _, index: 0 if index < 2500 else 1)(row, index) for index, row in df.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate labels and attributes\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df['label']\n",
    "\n",
    "X_train,X_validation,y_train,y_validation = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the generic classifier. This is the classifier with trivial parameters.\n",
    "# max_depth and max_sample_size will be adjusted afterwards.\n",
    "rf = RandomForestClassifier(oob_score=True,class_weight={0:1.43,1:3.33})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute best parameters in terms of accuracy, with GridSearchCV \n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid={\"max_depth\" : [i for i in range(5,30,5)],\"max_samples\": [i for i in range(500,4500,500)]},\n",
    "    cv=25,  # 25-fold cross-validation\n",
    "    scoring='balanced_accuracy',  \n",
    "    n_jobs=-1,  \n",
    "    verbose=1  \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "print(\"Best cross-validated scores:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will use oob as a measure and try to find best parameters again.\n",
    "#Note that since we are measuring one by one, we had to set max_depth to something.\n",
    "# We set max_depth to 15 because that was the most common value we got from gridsearch. Note that\n",
    "# it sometimes gives 13,15,20 etc. as beest depth.\n",
    "max_samples = [i for i in range(500, 5000,500)]\n",
    "\n",
    "\n",
    "oob_scores = []\n",
    "\n",
    "for sample in max_samples:\n",
    "    rf = RandomForestClassifier(\n",
    "        max_depth=15,\n",
    "        oob_score=True,\n",
    "        class_weight={0:1.43,1:3.33},\n",
    "        max_samples=sample\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    oob_scores.append(rf.oob_score_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_samples, oob_scores, marker='o', linestyle='-', color='b', label='OOB Score')\n",
    "plt.xlabel('Max Sample Size', fontsize=12)\n",
    "plt.ylabel('OOB Score', fontsize=12)\n",
    "plt.title('OOB Score vs Max Sample Size', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = grid_search.param_grid['max_depth']  # This is the range of depths tested in the grid\n",
    "\n",
    "\n",
    "oob_scores = []\n",
    "\n",
    "\n",
    "for depth in max_depths:\n",
    "    rf = RandomForestClassifier(\n",
    "        max_depth=depth,\n",
    "        oob_score=True,  \n",
    "        class_weight={0:1.43,1:3.33},\n",
    "        max_samples=3500\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    oob_scores.append(rf.oob_score_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, oob_scores, marker='o', linestyle='-', color='b', label='OOB Score')\n",
    "plt.xlabel('Max Depth', fontsize=12)\n",
    "plt.ylabel('OOB Score', fontsize=12)\n",
    "plt.title('OOB Score vs Max Depth', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the final rf, with tuned hyperparameters\n",
    "rf_final = RandomForestClassifier(\n",
    "        max_depth=15,\n",
    "        oob_score=True,  \n",
    "        class_weight={0:1.43,1:3.33},\n",
    "        max_samples=4000\n",
    "    )\n",
    "rf_final.fit(X_train,y_train)\n",
    "\n",
    "y_validation_pred = rf_final.predict(X_validation)\n",
    "\n",
    "oob_final = rf_final.oob_score_\n",
    "print(oob_final)\n",
    "\n",
    "accuracy = accuracy_score(y_validation, y_validation_pred)\n",
    "\n",
    "training_error = 1 - accuracy\n",
    "\n",
    "print(f\"Training error: {training_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_prb = rf.predict_proba(X_validation)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_validation, y_validation_prb, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color='gray')\n",
    "plt.xlabel('Fpr')\n",
    "plt.ylabel('Tpr')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2  = \"C:/Users/yusse/Documents/dataproject/trainData/32_test.csv\"\n",
    "test_set = pd.read_csv(path2, header=None)\n",
    "predictions = rf_final.predict(test_set)\n",
    "out_df = pd.DataFrame(predictions)\n",
    "out_df.to_csv('Group_32_Final_Predictions.csv',index=False,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
